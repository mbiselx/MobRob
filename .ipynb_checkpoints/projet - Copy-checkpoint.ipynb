{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Basics of Mobile Robotics Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect corner of the robot's environment\n",
    "We want to get rid off all the random components introduced by taking a picture by hand. it's include translations, rotations, scaling and most importantly perspective transformations. Therefore we want to search four points, which we willingly place at known distances and angles from each other, to standardize our image. \n",
    "\n",
    "The best is to detect the four extreme angles of the rectangle environment. It's increases the precision of the transformation (smaller relative error on their distance to each other).\n",
    "There are several ways to find these corner : \n",
    "\n",
    "- detect the lines of the rectangle (hough transform) but there will be to many line with obstacles.\n",
    "- convolution with the corner pattern in the grayscale (surprisingly not efficient at all) advantage of being scale invariant but not at all rotation invariant\n",
    "- convolution with specific pattern in the full color range (i.e. a pattern with a very specific color, easier to find) we chose a disk because it's rotation invariant the most important criter for convolution (not scale invarient but it's ok). by being the only object of a specific color in the plan it's supposed to be very easy to find but still some difficulties.\n",
    "\n",
    "We chose the last option, the more efficient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import libraries and define usefull functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage import morphology\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "np.random.seed(0) # To guarantee the same outcome on all computers\n",
    "\n",
    "\n",
    "#variable definition\n",
    "corner= np.zeros((4,2),np.uint32)  #matrix of the detected patterns' centers. int because thee are index\n",
    "corner_sort = np.zeros((4,2),np.uint32)  #sorted matrix of the detected patterns' centers\n",
    "distancex = 1200  #true distance of the robot environment\n",
    "distancey =  800  #true distance of the robot environment\n",
    "start = np.zeros(3,np.float32) #starting point of ther robot (x,y,angle). float to compute the angle\n",
    "end = np.zeros(2,np.int32) #goal point (x,y)\n",
    "centroid = np.zeros((2,3),np.int32) #centroids of the red disk and their number of points\n",
    "robot_size_kernel = (7,7)#kernel of the size of the robot in pixel in the resized map\n",
    "capt_point = (850,700)#point at which we emulate the sensing of an onboard camera\n",
    "capt_xdim = 200#dimension of the simulated camera view\n",
    "capt_ydim = 200\n",
    "path = 'photos_test_3\\IMG_5939.JPG'#if we take the image from the computer\n",
    "\n",
    "goalReached = -100#is goal reached? terminate the program\n",
    "capt_xdim = 200 #dimension of the emulated view, the bigger it is, the more the precision of the postion is\n",
    "capt_ydim = 200\n",
    "true_robot_length = 20#length between the center of the robot and a bit forward in pixels in the true map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#function definition\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "#Image processing functions__SART\n",
    "##################################################################################################\n",
    "def stackImages(scale, imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range(0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape[:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]),\n",
    "                                                None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y] = cv2.cvtColor(imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank] * rows\n",
    "        hor_con = [imageBlank] * rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None, scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor = np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "def display(output, fact = 0.3):\n",
    "    cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL )  # Create window with freedom of dimensions\n",
    "    cv2.resizeWindow(\"output\", math.floor ( fact * output.shape [1] ) , math.floor (fact * output.shape [0] ) )  # Resize window to specified dimensions keeping the image form\n",
    "    cv2.imshow(\"output\", output)\n",
    "    cv2.waitKey(0)\n",
    "def angle(x0,y0,x1,y1):\n",
    "    #directly put the angle in the start array\n",
    "    (x0 - x1)\n",
    "    (y0 - y1)\n",
    "    dist = math.sqrt ( (x0 - x1)*(x0 - x1) + (y0 - y1)*(y0 - y1)  )\n",
    "    x = (x1 - x0)/dist#normalisation required\n",
    "    start[2] = math.acos(x)\n",
    "def prepare_image(path):\n",
    "    #read the image saved in path and return it in RGB mode\n",
    "    img = cv2.imread(path)\n",
    "    u,v,d = img.shape\n",
    "    if (u>v):#if needed rotate the image to have a horizontal one\n",
    "        img = cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    return img\n",
    "\n",
    "def get_clean_map(img) :\n",
    "    #find the blue corner, make them wite, and map the image to get a nice map\n",
    "    #return true_map, the map in high resolution\n",
    "\n",
    "    #mask to get the blue color\n",
    "    imgHSV = cv2.cvtColor ( img , cv2.COLOR_BGR2HSV )\n",
    "    [h_min, s_min, v_min] = [90,138,108]\n",
    "    [h_max, s_max, v_max] = [130,255,255]\n",
    "    lower = np.array([h_min, s_min, v_min])\n",
    "    upper = np.array([h_max, s_max, v_max])\n",
    "    mask = cv2.inRange(imgHSV, lower, upper)\n",
    "\n",
    "    #for robustness and avoid useless labeling, remove all the noisy blue isolated pixels\n",
    "    img_erode = cv2.erode(mask,np.ones((4,4),np.uint8),iterations = 1)\n",
    "    img_dilate = cv2.dilate(img_erode,np.ones((4,4),np.uint8),iterations = 1)\n",
    "    #put the same number to all connected pixels:\n",
    "    labels = morphology.label(img_dilate, background=0)\n",
    "    #seek for the four biggest blobs i.e. the four labels with the most of pixels\n",
    "    #It's a robustness mesure : the four corners are supposed to have the same size and being much bigger than not wanted regions\n",
    "    unique_labels = (np.unique(labels))[1:]\n",
    "    comptage = np.zeros(unique_labels.size+1)\n",
    "    for i in unique_labels :\n",
    "        comptage[i] = np.sum(labels==i)\n",
    "    indice = np.argsort(comptage)\n",
    "\n",
    "    for i in range(0,4):#take the four biggest labels\n",
    "        ett_current = np.where(labels==(indice[indice.size-1-i]),1,0)\n",
    "        #erase the blue pixels not to detect them again\n",
    "        img [: , : , 0] = np.where ( labels == (indice [indice.size - 1 - i]) , 200 , img [: , : , 0] )\n",
    "        img [: , : , 1] = np.where ( labels == (indice [indice.size - 1 - i]) , 200 , img [: , : , 1] )\n",
    "        img [: , : , 2] = np.where ( labels == (indice [indice.size - 1 - i]) , 200 , img [: , : , 2] )\n",
    "        #compute the centroids of each blob, they are the corner of the map\n",
    "        ett_current = np.float32(ett_current)\n",
    "        M = cv2.moments (ett_current)\n",
    "        cX =  int ( M [\"m10\"] / M [\"m00\"] )\n",
    "        cY =  int ( M [\"m01\"] / M [\"m00\"] )\n",
    "        corner[i , :] = np.array([cX,cY])\n",
    "\n",
    "    #sort the corner\n",
    "    x_max = max(corner[:,0])\n",
    "    x_min = min(corner[:,0])\n",
    "    y_max = max(corner[:,1])\n",
    "    y_min = min(corner[:,1])\n",
    "    x_middle = (x_max-x_min)/2\n",
    "    y_middle = (y_max-y_min)/2\n",
    "    for i in range(0,4):\n",
    "        if (corner[i,0]<x_middle) & (corner[i,1]<y_middle):\n",
    "            corner_sort[0,:]=corner[i,:]\n",
    "        if (corner [i , 0] < x_middle) &  (corner [i , 1] > y_middle) :\n",
    "            corner_sort [1 , :] = corner [i , :]\n",
    "        if (corner [i , 0] > x_middle) &  (corner [i , 1] < y_middle) :\n",
    "            corner_sort [2 , :] = corner [i , :]\n",
    "        if (corner [i , 0] > x_middle) &  (corner [i , 1] > y_middle) :\n",
    "            corner_sort [3 , :] = corner [i , :]\n",
    "\n",
    "    #apply resizing\n",
    "    corner_goal = np.array([[0,0],[0,distancey], [distancex,0], [distancex,distancey]], np.float32)\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corner_sort),corner_goal)\n",
    "    img_reconstruct = cv2.warpPerspective(img, M,(distancex,distancey))\n",
    "    true_map = img_reconstruct\n",
    "    return true_map\n",
    "\n",
    "def robot_detection(map):\n",
    "    #return the position of the robot (x,y,angle) angle between the direction where the robot is going and the lower abscisse axis\n",
    "\n",
    "    #filter red component from the map\n",
    "    imgHSV2 = cv2.cvtColor ( map, cv2.COLOR_BGR2HSV )\n",
    "    [h_min , s_min , v_min] = [0 , 160 , 0]\n",
    "    [h_max , s_max , v_max] = [180 , 255 , 255]\n",
    "    lower = np.array ( [h_min , s_min , v_min] )\n",
    "    upper = np.array ( [h_max , s_max , v_max] )\n",
    "    mask = cv2.inRange ( imgHSV2 , lower , upper )\n",
    "\n",
    "    # detect the big and the small blob\n",
    "    img_erode = cv2.erode ( mask , np.ones ( (2 , 2) , np.uint8 ) , iterations=1 )\n",
    "    img_dilate = cv2.dilate ( img_erode , np.ones ( (2 , 2) , np.uint8 ) , iterations=1 )\n",
    "    labels = morphology.label ( img_dilate , background=0 )\n",
    "    unique_labels = (np.unique ( labels )) [1 :]\n",
    "    comptage = np.zeros ( unique_labels.size + 1 )\n",
    "    for i in unique_labels :\n",
    "        comptage [i] = np.sum ( labels == i )\n",
    "    indice = np.argsort ( comptage )\n",
    "\n",
    "    for i in range ( 0 , 2 ) :  # take the 2 biggest labels\n",
    "        ett_current = np.where ( labels == (indice [indice.size - 1 - i]) , 1 , 0 )\n",
    "        ett_current = np.float32 ( ett_current )\n",
    "        sum = np.sum ( ett_current )\n",
    "        M = cv2.moments ( ett_current )\n",
    "        cX = int ( M [\"m10\"] / M [\"m00\"] )\n",
    "        cY = int ( M [\"m01\"] / M [\"m00\"] )\n",
    "        centroid [i , :] = np.array ( [cX , cY , sum] )\n",
    "    #The biggest blob give the position (x,y) of the robot, we use also the small one to compute the angle\n",
    "    imax = np.argmax ( centroid [: , 2] )\n",
    "    imin = 1 - imax\n",
    "    start [0 :2] = centroid [imax , 0 :2]\n",
    "    angle ( centroid [0 , imax] , centroid [1 , imax] , centroid [0 , imin] , centroid [1 , imin] )\n",
    "    return start\n",
    "\n",
    "def goal_detection(img_reconstruct):\n",
    "    # detect the goal point\n",
    "\n",
    "    #filter the green component\n",
    "    imgHSV3 = cv2.cvtColor ( img_reconstruct , cv2.COLOR_BGR2HSV )\n",
    "    [h_min , s_min , v_min] = [47 , 89 , 51]\n",
    "    [h_max , s_max , v_max] = [116 , 209 , 198]\n",
    "    lower = np.array ( [h_min , s_min , v_min] )\n",
    "    upper = np.array ( [h_max , s_max , v_max] )\n",
    "    mask = cv2.inRange ( imgHSV3 , lower , upper )\n",
    "\n",
    "\n",
    "    #Here we consider there are not to much not wanted pixel in the mask\n",
    "    #so we consider after erosion the only pixels to one are those from the goal\n",
    "    img_erode = cv2.erode ( mask , np.ones ( (4 , 4) , np.uint8 ) , iterations=1 )\n",
    "    img_dilate = cv2.dilate ( img_erode , np.ones ( (4 , 4) , np.uint8 ) , iterations=1 )\n",
    "\n",
    "    M = cv2.moments ( img_dilate )\n",
    "    cX = int ( M [\"m10\"] / M [\"m00\"] )\n",
    "    cY = int ( M [\"m01\"] / M [\"m00\"] )\n",
    "    end = np.array ( [cX , cY] )\n",
    "    return end\n",
    "\n",
    "def get_global_search_map(for_global_search):\n",
    "    #return the map dilate to make obstacles a bit bigger to take into account the size of the robot\n",
    "\n",
    "    #here we get ride of all thin black lines used for online positioning\n",
    "    map_gray = cv2.cvtColor ( for_global_search , cv2.COLOR_BGR2GRAY )\n",
    "    map_dilate = cv2.dilate ( map_gray , np.ones ( (4 , 4) , np.uint8 ) , iterations=1 )\n",
    "    map_erode = cv2.erode ( map_dilate , np.ones ( (4 , 4) , np.uint8 ) , iterations=1 )\n",
    "\n",
    "    ret , map_bin = cv2.threshold ( map_erode , 50 , 255 , cv2.THRESH_BINARY )#apply a fixed threshold binarization\n",
    "    map_bin = 255 - map_bin\n",
    "    #increase the size of the obstacles\n",
    "    map_global_search = cv2.dilate ( map_bin , np.ones ( robot_size_kernel , np.uint8 ) , iterations=1 )\n",
    "    return map_global_search\n",
    "\n",
    "\n",
    "def camera_emulation(cap):\n",
    "    #emulate onboard camera return the emulated view, a rectangle a bit in front of the detected robot position\n",
    "        #detect robot's position\n",
    "    success, img = cap.read()#read the image from the  fixed camera\n",
    "    true_map = get_clean_map(img)#get the clean in good resolution\n",
    "    pos = robot_detection(true_map)#detect the position of the robot on the map\n",
    "\n",
    "        # crop the image to have a small rectangle in front of the robot\n",
    "    capt_point = np.array([pos[1]-capt_ydim,pos[0]]) + true_robot_length * np.array ([-math.sin ( pos[2] ) , math.cos ( pos[2] )])  # the bottom left point of the emulated view\n",
    "    capt_point = np.int32(capt_point)\n",
    "    #print('capt',capt_point)\n",
    "    capt_rect = true_map [capt_point [0] : capt_point [0] + capt_xdim , capt_point [1]  : capt_point [1] + capt_ydim]\n",
    "        #display the filmed region by highlighting it\n",
    "    true_map [capt_point [0] : capt_point [0] + capt_xdim , capt_point [1]  : capt_point [1] + capt_ydim] = true_map [capt_point [0] : capt_point [0] + capt_xdim , capt_point [1]  : capt_point [1] + capt_ydim]+40\n",
    "\n",
    "    # get the probable position of the robot by convolving the emulated view with the map\n",
    "    res = cv2.matchTemplate ( true_map , capt_rect , eval ( 'cv2.TM_CCOEFF_NORMED' ) )\n",
    "    min_val , max_val , min_loc , max_loc = cv2.minMaxLoc ( res )\n",
    "\n",
    "    #find the center of the robot from max_loc, top left point of convolution template\n",
    "    estimated_posx = max_loc[0]- math.floor(true_robot_length*math.cos ( pos[2] ))\n",
    "    estimated_posy = max_loc[1] + capt_ydim+ math.floor(true_robot_length*math.sin ( pos[2] ))\n",
    "    \n",
    "    \n",
    "    return np.array([estimated_posx, estimated_posy])\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "#Image processing functions___END\n",
    "##################################################################################################\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code we use the HSV representation to find the four blue corner and from them transform the image. Next we look for the orientation of the robot with the two red disk (two because we want position and orientation). Next we find the goal position with the green circle. And finally we determine a smaller version, binarized and with bit expnaded obstacles of the map to apply path finding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load img from computer\n",
    "img = prepare_image(path)#We load the image, we rotate it if needed to have a horizontal image.\n",
    "#or get it from the webcam\n",
    "#cap = cv2.VideoCapture(0)#put 1 if an external webcam is used\n",
    "#cap.set(3,1200)#width\n",
    "#cap.set(4,1000)#height\n",
    "#success, img = cap.read()\n",
    "#display(img)\n",
    "\n",
    "\n",
    "true_map = get_clean_map(img)\n",
    "for_global_search = cv2.resize(true_map, (200,100))#apply resizing to reduce computation cost of global search\n",
    "start = robot_detection(for_global_search)#starting point for global search\n",
    "end = goal_detection(for_global_search)#ending point for global search\n",
    "map_global_search = get_global_search_map(for_global_search)\n",
    "map_bin = map_global_search\n",
    "print('start :',start)\n",
    "print('goal :', end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_info(variable):\n",
    "    \"\"\"\n",
    "    Provided a variable, prints the type and content of the variable\n",
    "    \"\"\"\n",
    "    print(\"This variable is a {}\".format(type(variable)))\n",
    "    if type(variable) == np.ndarray:\n",
    "        print(\"\\n\\nThe shape is {}\".format(variable.shape))\n",
    "    print(\"\\n\\nThe data contained in the variable is : \")\n",
    "    print(variable)\n",
    "    print(\"\\n\\nThe elements that can be accessed in the variable are :\\n\")\n",
    "    print(dir(variable))\n",
    "    \n",
    "variable_info(np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_plot(max_val_row, max_val_column):\n",
    "    \"\"\"\n",
    "    Helper function to create a figure of the desired dimensions & grid\n",
    "    \n",
    "    :param max_val: dimension of the map along the x and y dimensions\n",
    "    :return: the fig and ax objects.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    \n",
    "    major_ticks_row = np.arange(0, max_val_row+1, 5)\n",
    "    minor_ticks_row = np.arange(0, max_val_row+1, 1)\n",
    "    major_ticks_column = np.arange(0, max_val_column+1, 5)\n",
    "    minor_ticks_column = np.arange(0, max_val_column+1, 1)\n",
    "    ax.set_xticks(major_ticks_column)\n",
    "    ax.set_xticks(minor_ticks_column, minor=True)\n",
    "    ax.set_yticks(major_ticks_row)\n",
    "    ax.set_yticks(minor_ticks_row, minor=True)\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    ax.set_ylim([0,max_val_row])\n",
    "    ax.set_xlim([0,max_val_column])\n",
    "    ax.grid(True)\n",
    "    \n",
    "    return fig, ax\n",
    "max_val_row=100\n",
    "max_val_column=200\n",
    "test=create_empty_plot(max_val_row, max_val_column)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_movements_4n():\n",
    "    \"\"\"\n",
    "    Get all possible 4-connectivity movements (up, down, left right).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0)]\n",
    "\n",
    "def _get_movements_8n():\n",
    "    \"\"\"\n",
    "    Get all possible 8-connectivity movements. Equivalent to get_movements_in_radius(1)\n",
    "    (up, down, left, right and the 4 diagonals).\n",
    "    :return: list of movements with cost [(dx, dy, movement_cost)]\n",
    "    \"\"\"\n",
    "    s2 = math.sqrt(2)\n",
    "    return [(1, 0, 1.0),\n",
    "            (0, 1, 1.0),\n",
    "            (-1, 0, 1.0),\n",
    "            (0, -1, 1.0),\n",
    "            (1, 1, s2),\n",
    "            (-1, 1, s2),\n",
    "            (-1, -1, s2),\n",
    "            (1, -1, s2)]\n",
    "\n",
    "movements=_get_movements_4n()\n",
    "for move in movements:\n",
    "    print(move[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_column = 200 # Size of the map\n",
    "max_val_row=100\n",
    "\n",
    "def A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"8N\", max_val_column=max_val_column, max_val_row=max_val_row):\n",
    "    \"\"\"\n",
    "    A* for 2D occupancy grid. Finds a path from start to goal.\n",
    "    h is the heuristic function. h(n) estimates the cost to reach goal from node n.\n",
    "    :param start: start node, tuple (x, y)\n",
    "    :param goal_m: goal node, tuple (x, y)\n",
    "    :param occupancy_grid: numpy array containing the map with the obstacles. At each position, \n",
    "                           you either have the number 1 (occupied) or 0 (free)\n",
    "    :param movement: string, select between 4-connectivity ('4N') and 8-connectivity ('8N', default)\n",
    "    :return: a tuple that contains: (the resulting path in meters, the resulting path in data array indices)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the start and goal are within the boundaries of the map\n",
    "#     for point in [start, goal]:\n",
    "#         assert point[0]>=0 and point[0]<max_val_column, \"start or end goal not contained in the map\"\n",
    "#         assert point[1]>=0 and point[1]<max_val_row, \"start or end goal not contained in the map\"\n",
    "    \n",
    "    # check if start and goal nodes correspond to free spaces\n",
    "    if occupancy_grid[start[0], start[1]]:\n",
    "        print(start[0], start[1])\n",
    "        raise Exception('Start node is not traversable')\n",
    "\n",
    "    if occupancy_grid[goal[0], goal[1]]:\n",
    "        print(goal[0], goal[1])\n",
    "        raise Exception('Goal node is not traversable')\n",
    "    \n",
    "    # get the possible movements corresponding to the selected connectivity\n",
    "    if movement_type == '4N':\n",
    "        movements = _get_movements_4n()\n",
    "    elif movement_type == '8N':\n",
    "        movements = _get_movements_8n()\n",
    "    else:\n",
    "        raise ValueError('Unknown movement')\n",
    "    \n",
    "    \n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    # A* Algorithm implementation - feel free to change the structure / use another pseudo-code\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # Here we initialise the variables, feel free to print them or use the variable info function if it is not\n",
    "    # what they contain or how to access the different elements\n",
    "    \n",
    "    # The set of visited nodes that need to be (re-)expanded, i.e. for which the neighbors need to be explored\n",
    "    # Initially, only the start node is known.\n",
    "    openSet = [start]\n",
    "    \n",
    "    # The set of visited nodes that no longer need to be expanded.\n",
    "    # Note that this is an addition w.r.t. the wikipedia pseudocode\n",
    "    # It contains the list of variables that have already been visited \n",
    "    # in order to visualise them in the plots\n",
    "    closedSet = []\n",
    "\n",
    "    # For node n, cameFrom[n] is the node immediately preceding it on the cheapest path from start to n currently known.\n",
    "    cameFrom = dict()\n",
    "\n",
    "    # For node n, gScore[n] is the cost of the cheapest path from start to n currently known.\n",
    "    gScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    gScore[start] = 0\n",
    "\n",
    "    # For node n, fScore[n] := gScore[n] + h(n). map with default value of Infinity\n",
    "    fScore = dict(zip(coords, [np.inf for x in range(len(coords))]))\n",
    "    fScore[start] = h[start]\n",
    "\n",
    "    \n",
    "    # while there are still nodes to visit (hint : change the while condition)\n",
    "    while len(openSet)!=0:\n",
    "        \n",
    "        #find the unvisited node having the lowest fScore[] value\n",
    "        node_min_fScore_value=np.inf\n",
    "        for node in openSet:\n",
    "            if fScore[node]<node_min_fScore_value:\n",
    "                node_min_fScore_value=fScore[node]\n",
    "                current=node\n",
    "        \n",
    "        #If the goal is reached, reconstruct and return the obtained path\n",
    "        if current==goal:\n",
    "            path=[goal]\n",
    "            while current!=start:\n",
    "                current=cameFrom[current]\n",
    "                path.append(current)\n",
    "            return path, closedSet\n",
    "        openSet.remove(current)\n",
    "        closedSet.append(current)\n",
    "        # If the goal was not reached, for each neighbor of current:\n",
    "        for dx, dy, deltacost in movements:\n",
    "            \n",
    "            neighbor = (current[0]+dx, current[1]+dy)\n",
    "            \n",
    "            # if the node is not in the map, skip\n",
    "            if neighbor not in coords:\n",
    "                continue\n",
    "                \n",
    "            # if the node is occupied or has already been visited, skip\n",
    "            if occupancy_grid[neighbor[0], neighbor[1]] or neighbor in closedSet:\n",
    "                continue\n",
    "                \n",
    "            # compute the cost to reach the node through the given path\n",
    "            tentative_gScore = gScore[current]+deltacost\n",
    "            \n",
    "            # If the computed cost is the best one for that node, then update the costs and \n",
    "            #Â node from which it came\n",
    "            if tentative_gScore<gScore[neighbor]:\n",
    "                # This path to neighbor is better than any previous one. Record it!\n",
    "                cameFrom[neighbor]=current\n",
    "                gScore[neighbor]=tentative_gScore\n",
    "                fScore[neighbor]=gScore[neighbor]+h[neighbor]\n",
    "                if neighbor not in openSet:\n",
    "                    openSet.append(neighbor)\n",
    "\n",
    "    # Open set is empty but goal was never reached\n",
    "    print(\"No path found to goal\")\n",
    "    return [], [] #DUMMY VALUE - TO BE CHANGED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_global_path(start, goal, occupancy_grid):    \n",
    "    max_val_row=occupancy_grid.shape[0]\n",
    "    max_val_column=occupancy_grid.shape[1]\n",
    "    # EXECUTION AND PLOTTING OF THE ALGORITHM     \n",
    "    # List of all coordinates in the grid\n",
    "    x,y=np.mgrid[0:max_val_column:1, 0:max_val_row:1]\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:,:,0] = y \n",
    "    pos[:,:,1] = x\n",
    "    pos = np.reshape(pos, (x.shape[0]*x.shape[1], 2))\n",
    "    coords = list([(int(x[0]), int(x[1])) for x in pos])\n",
    "\n",
    "\n",
    "    # Define the heuristic, here = distance to goal ignoring obstacles\n",
    "    h = np.linalg.norm(pos - goal, axis=-1)\n",
    "    # print(h)\n",
    "    h = dict(zip(coords, h))\n",
    "    # print(h)\n",
    "\n",
    "    # Run the A* algorithm\n",
    "    path, visitedNodes = A_Star(start, goal, h, coords, occupancy_grid, movement_type=\"8N\")\n",
    "    path = np.array(path).reshape(-1, 2).transpose()\n",
    "    visitedNodes = np.array(visitedNodes).reshape(-1, 2).transpose()\n",
    "\n",
    "    # Displaying the map\n",
    "    fig_astar, ax_astar = create_empty_plot(max_val_row, max_val_column)\n",
    "    ax_astar.imshow(occupancy_grid, cmap=colors.ListedColormap(['white', 'red']))\n",
    "\n",
    "    # Plot the best path found and the list of visited nodes\n",
    "    ax_astar.scatter(visitedNodes[1], visitedNodes[0], marker=\"o\", color = 'orange');\n",
    "    ax_astar.plot(path[1], path[0], marker=\"o\", color = 'blue');\n",
    "    ax_astar.scatter(start[1], start[0], marker=\"o\", color = 'green', s=200);\n",
    "    ax_astar.scatter(goal[1], goal[0], marker=\"o\", color = 'purple', s=200);\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "occupancy_grid = np.asarray(map_bin)\n",
    "occupancy_grid = np.flipud(occupancy_grid)\n",
    "print(start)\n",
    "# start=[20, 80]\n",
    "start = np.int32(start)\n",
    "print('new start', (occupancy_grid.shape[0]-start[1], start[0]))\n",
    "print(end)\n",
    "print('new goal', (occupancy_grid.shape[0]-end[1], end[0]))\n",
    "print(occupancy_grid.shape)\n",
    "path=generate_global_path((occupancy_grid.shape[0]-start[1], start[0]), (occupancy_grid.shape[0]-end[1], end[0]), occupancy_grid)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get into the navigtion of the robot\n",
    "\n",
    "Emulating an onboard camera. In order to compensate the bad sensors of the robot it would have been interesting to have on onboard camera looking to the floor a bit forward to the robot. But it would have been difficult to put a camera on the thymio and the image we get would have undesired rotation and transformation. it's possible to fix it but it add to complexity to the project. \n",
    "So we decided to emulate an onboard camera, by a fixed one above the table, looking at the whole map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#or get it from the webcam\n",
    "cap = cv2.VideoCapture(1)#put 1 if an external webcam is used\n",
    "cap.set(3,1200)#width\n",
    "cap.set(4,1000)#height\n",
    "success, img = cap.read()\n",
    "display(img)\n",
    "\n",
    "true_map = get_clean_map(img)\n",
    "for_global_search = cv2.resize(true_map, (200,100))#apply resizing to reduce computation cost of global search\n",
    "start = robot_detection(for_global_search)#starting point for global search\n",
    "print('start :',start)\n",
    "print('goal :', end)\n",
    "\n",
    "goalReached = -100\n",
    "capt_xdim = 200\n",
    "capt_ydim = 200\n",
    "true_robot_length = 20\n",
    "\n",
    "pos = robot_detection ( true_map )\n",
    "\n",
    "\n",
    "while goalReached!=1:\n",
    "    \n",
    "    print(np.array([camera_emulation(cap)]).T)\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import serial\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from threading import Timer\n",
    "from IPython import display as ds\n",
    "\n",
    "# Adding the src folder in the current directory as it contains \n",
    "# the necessary scripts\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "from Thymio import Thymio\n",
    "import Field\n",
    "import Robot\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepeatedTimer(object):\n",
    "    def __init__(self, interval, function, *args, **kwargs):\n",
    "        self._timer     = None\n",
    "        self.interval   = interval\n",
    "        self.function   = function\n",
    "        self.args       = args\n",
    "        self.kwargs     = kwargs\n",
    "        self.is_running = False\n",
    "        self.start()\n",
    "\n",
    "    def _run(self):\n",
    "        self.is_running = False\n",
    "        self.start()\n",
    "        self.function(*self.args, **self.kwargs)\n",
    "\n",
    "    def start(self):\n",
    "        if not self.is_running:\n",
    "            self._timer = Timer(self.interval, self._run)\n",
    "            self._timer.start()\n",
    "            self.is_running = True\n",
    "\n",
    "    def stop(self):\n",
    "        self._timer.cancel()\n",
    "        self.is_running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot      = Robot.NewRobot()                                                   # robot \n",
    "field      = Field.NewField(1200, 800, 200, 4)                                  # table\n",
    "\n",
    "field.goals= [[500, 300], [700, 700], [1100, 100], [300, 500], [700, 700], [1100, 100]]     # set a bunch of goals\n",
    "startpos   = np.array([[100], [100], [np.pi/4], [0], [0]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.th   = Thymio.serial(port=\"COM15\", refreshing_rate=0.1)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_thread(field, robot, goals, camera_pos):\n",
    "    \n",
    "        u = robot.pilot(goals)\n",
    "\n",
    "        robot.do_motion(u)\n",
    "        \n",
    "        sensor_data = robot.do_measure()\n",
    "\n",
    "        y = robot.sensor_interpretation(sensor_data, field)\n",
    "        \n",
    "        if camera_pos.x.size :  # if a camera position is available, update\n",
    "            c0 = np.concatenate((np.eye(3), np.zeros((3,2))), axis = 1)\n",
    "            y0 = np.array([camera_pos.x[0:3,:]]).T\n",
    "            r0 = np.array([25, 25, .5])**2\n",
    "            robot.R = np.diag(np.concatenate((r0, np.diag(robot.R)), axis=0))  \n",
    "            robot.C = np.concatenate((c0, robot.C))\n",
    "            y = np.concatenate((y0, y), axis=0)\n",
    "            camera_pos.x = np.array([])\n",
    "        \n",
    "        xtemp, stemp = robot.kalman_estimator(u, y)\n",
    "            \n",
    "        robot.xodo = robot.motion_model(robot.xodo, u) #make a purely odometry-based estimate, for visual comparison\n",
    "        \n",
    "        field.xhat  = np.concatenate((field.xhat, xtemp), axis=1)\n",
    "        field.xodo  = np.concatenate((field.xodo, robot.xodo), axis=1)\n",
    "        field.s.append(2*np.sqrt(stemp[0,0]+stemp[1,1]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_thread(field, cap, camera_pos) : \n",
    "    \n",
    "    success, img = cap.read()                    #read the image from the  fixed camera\n",
    "    true_map     = get_clean_map(img)            #get the clean in good resolution\n",
    "    x            = robot_detection(true_map)     #detect the position of the robot on the map\n",
    "    \n",
    "    x = np.concatenate((np.array([x]).T, np.zeros((2,1))), axis=0)\n",
    "    x[1,:] = field.ymax - x[1,:]\n",
    "    x[2,:] =            - x[2,:]\n",
    "\n",
    "    field.xreal = np.concatenate((field.xreal, x), axis=1)\n",
    "    camera_pos.x = x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#setup vision\n",
    "cap = cv2.VideoCapture(1)#put 1 if an external webcam is used\n",
    "cap.set(3,1200)#width\n",
    "cap.set(4,1000)#height\n",
    "success, img = cap.read()\n",
    "#display(img)\n",
    "\n",
    "true_map = get_clean_map(img)\n",
    "for_global_search = cv2.resize(true_map, (200,100))  #apply resizing to reduce computation cost of global search\n",
    "start = robot_detection(for_global_search)           #starting point for global search\n",
    "\n",
    "\n",
    "\n",
    "Tr = .2                                                                          # robot update timestep\n",
    "Tc =  2                                                                          # camera update timestep\n",
    "\n",
    "startpos = np.concatenate((np.array([start]).T, np.zeros((2,1))))\n",
    "startpos[1,:] = field.ymax - startpos[1,:] \n",
    "startpos[2,:] =            - startpos[2,:] \n",
    "robot.xhat = startpos.copy()                                                     # setup robot\n",
    "robot.xodo = startpos.copy()\n",
    "robot.s    = np.diag([25, 25, .5, 20, 20])**2\n",
    "\n",
    "robot.set_Ts(Tr)\n",
    "robot.maxv=20\n",
    "robot.maxw=np.pi/2\n",
    "\n",
    "field.xreal = startpos.copy()                                                    # prepare record of (mis)deeds\n",
    "field.xhat  = robot.xhat.copy()\n",
    "field.xodo  = robot.xodo.copy()\n",
    "field.s     = [2*np.sqrt(robot.s[0,0]+robot.s[1,1])]\n",
    "\n",
    "goals = field.goals.copy()\n",
    "\n",
    "\n",
    "class Camera_Pos :\n",
    "    def __init__ (self): \n",
    "        pass\n",
    "\n",
    "camera_pos = Camera_Pos()\n",
    "camera_pos.x = np.array([])                                                      # communication variable\n",
    "\n",
    "rt = RepeatedTimer(Tr, robot_thread,  field, robot, goals, camera_pos);\n",
    "ct = RepeatedTimer(Tc, camera_thread, field, cap, camera_pos);\n",
    "\n",
    "try:\n",
    "    print(\"Starting Run\")  \n",
    "    for i in range(20):\n",
    "        time.sleep(1) \n",
    "        plt.clf();\n",
    "        plt.gcf().set_size_inches(9,6)\n",
    "        field.plot()\n",
    "        ds.display(plt.gcf())\n",
    "        ds.clear_output(wait=True)\n",
    "\n",
    "finally:\n",
    "    rt.stop()\n",
    "    ct.stop()\n",
    "    robot.do_motion(np.zeros((2,1)))\n",
    "    print(\"Done\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "robot.do_motion(np.zeros((2,1)))\n",
    "robot.th.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(9,6)\n",
    "\n",
    "field.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
